{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"read_write_json\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi line json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+----------------+-----------------+-------+\n",
      "|                 bio|              id|        language|             name|version|\n",
      "+--------------------+----------------+----------------+-----------------+-------+\n",
      "|Donec lobortis el...|V59OF92YF627HFY0|          Sindhi|    Adeel Solangi|    6.1|\n",
      "|Aliquam sollicitu...|ENTOCR13RSCLZ6KU|          Sindhi|    Afzal Ghaffar|   1.88|\n",
      "|Vestibulum pharet...|IAKPO3R4761JDRVG|          Sindhi|    Aamir Solangi|   7.27|\n",
      "|Donec lobortis el...|5ZVOEPMJUI4MB4EN|          Uyghur|    Abla Dilmurat|   2.53|\n",
      "|Vivamus id faucib...|6VTI8X6LL0MMPJCC|          Uyghur|         Adil Eli|   6.49|\n",
      "|Duis commodo orci...|F2KEU5L7EHYSYFTT|          Uyghur|      Adile Qadir|    1.9|\n",
      "|Vivamus id faucib...|LO6DVTZLRK68528I|          Uyghur|Abdukerim Ibrahim|    5.9|\n",
      "|Etiam malesuada b...|LJRIULRNJFCNZJAJ|          Sindhi|        Adil Abro|   9.32|\n",
      "|Fusce eu ultrices...|JMCL0CXNXHPL1GBC|        Galician| Afonso Vilarchán|   5.21|\n",
      "|Nam laoreet, nunc...|KU4T500C830697CW|         Maltese|    Mark Schembri|   3.17|\n",
      "|Pellentesque mass...|XOF91ZR7MHV1TXRS|        Galician|    Antía Sixirei|   6.44|\n",
      "|Duis commodo orci...|FTSNV411G5MKLPDT|          Uyghur|   Aygul Mutellip|    9.1|\n",
      "|Nunc aliquet soda...|OJMWMEEQWMLDU29P|          Sindhi|     Awais Shaikh|   1.59|\n",
      "|Vestibulum ante i...|5G646V7E6TJW8X2M|          Sindhi|    Ambreen Ahmed|   2.35|\n",
      "|Nullam ac sodales...|Z53AJY7WUYPLAWC9|        Galician|      Celtia Anes|   8.34|\n",
      "|Phasellus tincidu...|N1AS6UFULO6WGTLB|         Maltese|    George Mifsud|   7.47|\n",
      "|Curabitur ultrici...|70RODUVRD95CLOJL|          Uyghur|     Aytürk Qasim|   1.32|\n",
      "|Maecenas non arcu...|VBLI24FKF7VV6BWE|Sesotho sa Leboa|       Dialè Meso|   6.29|\n",
      "|Integer vehicula,...|4VRLON0GPEZYFCVL|        Galician|    Breixo Galáns|   1.62|\n",
      "|Ut viverra quis e...|5DRDI1QLRGLP29RC|        Galician|     Bieito Lorme|   4.45|\n",
      "+--------------------+----------------+----------------+-----------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "df = spark.read.option(\"multiline\", \"true\").json(path=r'C:\\Users\\saipr\\software\\python\\workspace\\PySpark_Project\\data_files\\json\\multiline.json')\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read multiple json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-------+\n",
      "|age|         city|   name|\n",
      "+---+-------------+-------+\n",
      "| 30|     New York|    sai|\n",
      "| 25|      Chicago|pradeep|\n",
      "| 35|San Francisco| baggam|\n",
      "| 30|     New York|   John|\n",
      "| 25|      Chicago|   Jane|\n",
      "| 35|San Francisco|   Mike|\n",
      "+---+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json([r'C:\\Users\\saipr\\software\\python\\workspace\\PySpark_Project\\data_files\\json\\emp1.json',\n",
    "                      r'C:\\Users\\saipr\\software\\python\\workspace\\PySpark_Project\\data_files\\json\\emp2.json'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read multiple jsons in a location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType().add(field='age',dataType=IntegerType())\\\n",
    "                     .add(field='city',dataType=StringType())\\\n",
    "                     .add(field='name',dataType=StringType()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(r'C:\\Users\\saipr\\software\\python\\workspace\\PySpark_Project\\data_files\\json\\emp*.json',schema=schema_of_csv)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"name\": \"John\", \"age\": 30, \"city\": \"New York\"},\n",
    "    {\"name\": \"Jane\", \"age\": 25, \"city\": \"Chicago\"},\n",
    "    {\"name\": \"Mike\", \"age\": 35, \"city\": \"San Francisco\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data)\n",
    "\n",
    "df_json = df.write.json(r'C:\\Users\\saipr\\software\\python\\workspace\\PySpark_Project\\data_files\\output\\employees.json')\n",
    "\n",
    "df_json.show()\n",
    "\n",
    "df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_project_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
