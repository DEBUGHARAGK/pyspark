{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Date_functions\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.range(2)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "| id|current_date|\n",
      "+---+------------+\n",
      "|  0|  2024-08-13|\n",
      "|  1|  2024-08-13|\n",
      "+---+------------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- current_date: date (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_date,date_format\n",
    "\n",
    "df1 = df.withColumn(\"current_date\", current_date())\n",
    "df1.show()\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-------------------+\n",
      "| id|current_date|current_date_string|\n",
      "+---+------------+-------------------+\n",
      "|  0|  2024-08-13|         2024.08.13|\n",
      "|  1|  2024-08-13|         2024.08.13|\n",
      "+---+------------+-------------------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- current_date: date (nullable = false)\n",
      " |-- current_date_string: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df1.withColumn('current_date_string',date_format(df1.current_date,'yyyy.MM.dd'))\n",
    "df2.show()\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-------------------+----------+\n",
      "| id|current_date|current_date_string|  cur_date|\n",
      "+---+------------+-------------------+----------+\n",
      "|  0|  2024-08-13|         2024.08.13|2024-08-13|\n",
      "|  1|  2024-08-13|         2024.08.13|2024-08-13|\n",
      "+---+------------+-------------------+----------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- current_date: date (nullable = false)\n",
      " |-- current_date_string: string (nullable = false)\n",
      " |-- cur_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_date,date_format,to_date\n",
    "\n",
    "df3 = df2.withColumn('cur_date',to_date(df2.current_date_string,'yyyy.MM.dd'))\n",
    "df3.show()\n",
    "df3.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import datediff,months_between,add_months,date_add\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|        d1|        d2|\n",
      "+----------+----------+\n",
      "|2024-08-23|2024-09-23|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [('2024-08-23','2024-09-23')]\n",
    "schema = ['d1','d2']\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+\n",
      "|        d1|        d2|datediff|\n",
      "+----------+----------+--------+\n",
      "|2024-08-23|2024-09-23|      31|\n",
      "+----------+----------+--------+\n",
      "\n",
      "root\n",
      " |-- d1: string (nullable = true)\n",
      " |-- d2: string (nullable = true)\n",
      " |-- datediff: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df.withColumn('datediff', datediff(df.d2,df.d1))\n",
    "df1.show()\n",
    "\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+--------------+\n",
      "|        d1|        d2|datediff|months_between|\n",
      "+----------+----------+--------+--------------+\n",
      "|2024-08-23|2024-09-23|      31|           1.0|\n",
      "+----------+----------+--------+--------------+\n",
      "\n",
      "root\n",
      " |-- d1: string (nullable = true)\n",
      " |-- d2: string (nullable = true)\n",
      " |-- datediff: integer (nullable = true)\n",
      " |-- months_between: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df1.withColumn('months_between', months_between(df.d2,df.d1))\n",
    "df2.show()\n",
    "\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+--------------+----------+\n",
      "|        d1|        d2|datediff|months_between|add_months|\n",
      "+----------+----------+--------+--------------+----------+\n",
      "|2024-08-23|2024-09-23|      31|           1.0|2024-12-23|\n",
      "+----------+----------+--------+--------------+----------+\n",
      "\n",
      "+----------+----------+--------+--------------+----------+----------+\n",
      "|        d1|        d2|datediff|months_between|add_months|sub_months|\n",
      "+----------+----------+--------+--------------+----------+----------+\n",
      "|2024-08-23|2024-09-23|      31|           1.0|2024-12-23|2024-03-23|\n",
      "+----------+----------+--------+--------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df2.withColumn('add_months', add_months(df.d2,3))\n",
    "df4 = df3.withColumn('sub_months', add_months(df.d2,-6))\n",
    "df3.show()\n",
    "df4.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+--------------+----------+----------+----------+\n",
      "|        d1|        d2|datediff|months_between|add_months|sub_months|  days_add|\n",
      "+----------+----------+--------+--------------+----------+----------+----------+\n",
      "|2024-08-23|2024-09-23|      31|           1.0|2024-12-23|2024-03-23|2024-09-29|\n",
      "+----------+----------+--------+--------------+----------+----------+----------+\n",
      "\n",
      "+----------+----------+--------+--------------+----------+----------+----------+\n",
      "|        d1|        d2|datediff|months_between|add_months|sub_months|  days_add|\n",
      "+----------+----------+--------+--------------+----------+----------+----------+\n",
      "|2024-08-23|2024-09-23|      31|           1.0|2024-12-23|2024-03-23|2024-09-17|\n",
      "+----------+----------+--------+--------------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5 = df4.withColumn('days_add', date_add(df.d2,6)).show()\n",
    "df5 = df4.withColumn('days_add', date_add(df.d2,-6)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+--------------+----------+----------+----+\n",
      "|        d1|        d2|datediff|months_between|add_months|sub_months|year|\n",
      "+----------+----------+--------+--------------+----------+----------+----+\n",
      "|2024-08-23|2024-09-23|      31|           1.0|2024-12-23|2024-03-23|2024|\n",
      "+----------+----------+--------+--------------+----------+----------+----+\n",
      "\n",
      "+----------+----------+--------+--------------+----------+----------+-----+\n",
      "|        d1|        d2|datediff|months_between|add_months|sub_months|month|\n",
      "+----------+----------+--------+--------------+----------+----------+-----+\n",
      "|2024-08-23|2024-09-23|      31|           1.0|2024-12-23|2024-03-23|    9|\n",
      "+----------+----------+--------+--------------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import datediff,months_between,add_months,date_add,year,month\n",
    "\n",
    "df5 = df4.withColumn('year', year(df.d2)).show()\n",
    "df5 = df4.withColumn('month', month(df.d2)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------+\n",
      "|id |convert_timestamp      |\n",
      "+---+-----------------------+\n",
      "|0  |2024-08-13 18:03:23.132|\n",
      "|1  |2024-08-13 18:03:23.132|\n",
      "+---+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp,lit,col\n",
    "\n",
    "# Convert timestamp string to actual timestamp with correct format\n",
    "df_with_timestamp = df.withColumn(\n",
    "    'convert_timestamp', \n",
    "    to_timestamp(lit('2024.08.13 18.03.23.132'), 'yyyy.MM.dd HH.mm.ss.SSS')\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "df_with_timestamp.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------+----+------+------+\n",
      "|id |convert_timestamp      |hour|minute|second|\n",
      "+---+-----------------------+----+------+------+\n",
      "|0  |2024-08-13 18:03:23.132|18  |3     |23    |\n",
      "|1  |2024-08-13 18:03:23.132|18  |3     |23    |\n",
      "+---+-----------------------+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import hour,minute,second\n",
    "df_final = df_with_timestamp.select('*',hour(df_with_timestamp.convert_timestamp).alias('hour')\n",
    "                                       ,minute(df_with_timestamp.convert_timestamp).alias('minute')\n",
    "                                       ,second(df_with_timestamp.convert_timestamp).alias('second')\n",
    "                                       )\n",
    "df_final.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_project_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
